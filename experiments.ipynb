{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 200%; text-align: center; border-radius: 10px 10px;\">Task 0 - Libraries</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 150%; text-align: center; border-radius: 10px 10px;\">0.1 - General Purpose</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 150%; text-align: center; border-radius: 10px 10px;\">0.2 - Exploration</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 150%; text-align: center; border-radius: 10px 10px;\">0.3 - Preprocessing</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 150%; text-align: center; border-radius: 10px 10px;\">0.4 - Baseline</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 150%; text-align: center; border-radius: 10px 10px;\">0.5 - Neural Network</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from skorch import NeuralNetRegressor\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 150%; text-align: center; border-radius: 10px 10px;\">0.6 - Evaluation</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 150%; text-align: center; border-radius: 10px 10px;\">0.7 - Reproducibility</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(1)\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 200%; text-align: center; border-radius: 10px 10px;\">Task 1 - Story</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing StreetEasy - reimagining the way people buy, sell, and rent real estate across New York City and New Jersey. Incorporating intuitive search tools and insightful data-driven content, we strive to bridge the gap between would-be renters or buyers and landlords. Whether you are listing or hunting, we will cater to your needs from start to finish. The use of data science in such catering is on the rise.\n",
    "\n",
    "My role as a data scientist contributes to real estate marketing efforts, catering pricing strategies to stimulate seeker-landlord interactions. Current research centers around listing-based machine learning. An associated regression problem was introduced, involving the estimation of rental prices by neural networks. Real estate hotspot Manhattan constitutes the focal point of initial experiments.\n",
    "\n",
    "Experiments for a suitable regressor, consulting multiple neural network architectures. Architectures are therefore explored in search of a reliable estimator. Reliability serves as an indicator for prospective project scaling. Scaling is desirable as reliable estimates, could drive pricing strategies, increasing landlord-tenant interaction. Resulting rise in traffic culminates in landlord interest, translating into greater revenue from listing fees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 200%; text-align: center; border-radius: 10px 10px;\">Task 2 - The Data</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following chapter details the __[dataset](https://www.kaggle.com/datasets/zohaib30/streeteasy-dataset/data)__ considered for the regression experiment. More specifically, it will be outlined what it consists of and how it might fit within the experiment context. Should the __[dataset](https://www.kaggle.com/datasets/zohaib30/streeteasy-dataset/data)__ appear valid according to that outline, it will be used in the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 150%; text-align: center; border-radius: 10px 10px;\">2.1 - Features</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "|Feature|Description|\n",
    "|:----:|:----:|\n",
    "|rental_id|Identifier unique to the rental listing.|\n",
    "|rent|Price of the rental listing in US dollars per month.|\n",
    "|bedrooms|Bedrooms located within the rental listing.|\n",
    "|bathrooms|Bathrooms located within the rental listing.|\n",
    "|size_sqft|Size of the rental listing in square feet.|\n",
    "|min_to_subway|Distance of the rental listing to a subway station in minutes.|\n",
    "|floor|Level within the building on which the rental listing is located.|\n",
    "|building_age_yrs|Time elapsed since the construction of the building for the rental listing in years.|\n",
    "|no_fee|Denotes the presence of charges associated with potential brokers for the rental listing.|\n",
    "|has_roofdeck|Denotes the presence of a flat, terraced roof section on the rental listing building.|\n",
    "|has_washer_dryer|Denotes the presence of a machine dedicated to washing and drying cloth within the rental listing.|\n",
    "|has_doorman|Denotes the presence of staff dedicated to regulating access to the rental listing building.|\n",
    "|has_elevator|Denotes the presence of a room dedicated to ferrying passengers up and down the rental listing building.|\n",
    "|has_dishwasher|Denotes the presence of a machine dedicated to washing dishes within the rental listing.|\n",
    "|has_patio|Denotes the presence of a solid-floored outside area adjoining the ground floor of the rental listing building.|\n",
    "|has_gym|Denotes the presence of an area equipped with exercise tools within the rental listing building.|\n",
    "|neighborhood|Geographic subarea of a borough where the rental listing building is located.|\n",
    "|borough|Division of New York City where the rental listing building is located.|\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 150%; text-align: center; border-radius: 10px 10px;\">2.2 - Experiment Context</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StreetEasy's real estate vertical constitutes the subject of the __[dataset](https://www.kaggle.com/datasets/zohaib30/streeteasy-dataset/data)__, whose instances are labelled with rent rates. Features define property details, whereas instances reflect observed rental listings. Those rental listings observed pertain exclusively to the Manhattan borough.\n",
    "\n",
    "In light of the property details, input features, for pattern recognition, may be available. As these are features of rental properties in Manhattan, the vertical requirement is met. Moreover, rental rate-labeled instances, posing targets, are at disposal, enabling regression tasks. This provides a sound base to engineer neural networks, solving the desired regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 150%; text-align: center; border-radius: 10px 10px;\">2.3 - Loading Dataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath_or_buffer = \"manhattan.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, the relevant dataset for the regression experiment is read and stored as df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 200%; text-align: center; border-radius: 10px 10px;\">Task 3 - IDA</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The upcoming chapter lays the groundwork for explanatory analysis and preprocessing. Hence, an overview of the __[dataset](https://www.kaggle.com/datasets/zohaib30/streeteasy-dataset/data)__'s structural, qualitative, and statistical properties is established. Starting with the basic structure, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rental_id</th>\n",
       "      <th>rent</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>size_sqft</th>\n",
       "      <th>min_to_subway</th>\n",
       "      <th>floor</th>\n",
       "      <th>building_age_yrs</th>\n",
       "      <th>no_fee</th>\n",
       "      <th>has_roofdeck</th>\n",
       "      <th>has_washer_dryer</th>\n",
       "      <th>has_doorman</th>\n",
       "      <th>has_elevator</th>\n",
       "      <th>has_dishwasher</th>\n",
       "      <th>has_patio</th>\n",
       "      <th>has_gym</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1545</td>\n",
       "      <td>2550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>480</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Upper East Side</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2472</td>\n",
       "      <td>11500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Greenwich Village</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2919</td>\n",
       "      <td>4500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>916</td>\n",
       "      <td>2</td>\n",
       "      <td>51.0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2790</td>\n",
       "      <td>4795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>975</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Greenwich Village</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3946</td>\n",
       "      <td>17500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4800</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Soho</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10817</td>\n",
       "      <td>3800</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Central Harlem</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9077</td>\n",
       "      <td>1995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Midtown East</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5150</td>\n",
       "      <td>2995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>579</td>\n",
       "      <td>6</td>\n",
       "      <td>21.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Battery Park City</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9507</td>\n",
       "      <td>15000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Flatiron</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1437</td>\n",
       "      <td>4650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>915</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Upper East Side</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rental_id   rent  bedrooms  bathrooms  size_sqft  min_to_subway  floor   \n",
       "0       1545   2550       0.0          1        480              9    2.0  \\\n",
       "1       2472  11500       2.0          2       2000              4    1.0   \n",
       "2       2919   4500       1.0          1        916              2   51.0   \n",
       "3       2790   4795       1.0          1        975              3    8.0   \n",
       "4       3946  17500       2.0          2       4800              3    4.0   \n",
       "5      10817   3800       3.0          2       1100              3    5.0   \n",
       "6       9077   1995       0.0          0        600              6    1.0   \n",
       "7       5150   2995       0.0          1        579              6   21.0   \n",
       "8       9507  15000       2.0          2       1715              0   30.0   \n",
       "9       1437   4650       1.0          1        915              5    5.0   \n",
       "\n",
       "   building_age_yrs  no_fee  has_roofdeck  has_washer_dryer  has_doorman   \n",
       "0                17       1             1                 0            0  \\\n",
       "1                96       0             0                 0            0   \n",
       "2                29       0             1                 0            1   \n",
       "3                31       0             0                 0            1   \n",
       "4               136       0             0                 0            1   \n",
       "5               101       0             0                 0            0   \n",
       "6               115       0             0                 0            0   \n",
       "7                33       0             0                 0            0   \n",
       "8                 2       0             0                 0            0   \n",
       "9               106       0             0                 0            0   \n",
       "\n",
       "   has_elevator  has_dishwasher  has_patio  has_gym       neighborhood   \n",
       "0             1               1          0        1    Upper East Side  \\\n",
       "1             0               0          0        0  Greenwich Village   \n",
       "2             1               1          0        0            Midtown   \n",
       "3             1               1          0        1  Greenwich Village   \n",
       "4             1               1          0        1               Soho   \n",
       "5             0               0          0        0     Central Harlem   \n",
       "6             0               0          0        0       Midtown East   \n",
       "7             0               0          0        0  Battery Park City   \n",
       "8             0               0          0        0           Flatiron   \n",
       "9             0               0          0        0    Upper East Side   \n",
       "\n",
       "     borough  \n",
       "0  Manhattan  \n",
       "1  Manhattan  \n",
       "2  Manhattan  \n",
       "3  Manhattan  \n",
       "4  Manhattan  \n",
       "5  Manhattan  \n",
       "6  Manhattan  \n",
       "7  Manhattan  \n",
       "8  Manhattan  \n",
       "9  Manhattan  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features **_rental_id_**, **_neighborhood_**, and **_borough_** immediately catch the eye. **_Rental_id_** introduces redundancy to the index, granting discriminatory power in accessing. Yet no discriminatory power relating to the regression problem, causing noise. While **_borough_** is supposedly exclusive to Manhattan, implying absence of discriminatory power. Such a borough consists of neighborhoods, categorical by nature and thereby vulnerable to rare occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3539 entries, 0 to 3538\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   rental_id         3539 non-null   int64  \n",
      " 1   rent              3539 non-null   int64  \n",
      " 2   bedrooms          3539 non-null   float64\n",
      " 3   bathrooms         3539 non-null   int64  \n",
      " 4   size_sqft         3539 non-null   int64  \n",
      " 5   min_to_subway     3539 non-null   int64  \n",
      " 6   floor             3539 non-null   float64\n",
      " 7   building_age_yrs  3539 non-null   int64  \n",
      " 8   no_fee            3539 non-null   int64  \n",
      " 9   has_roofdeck      3539 non-null   int64  \n",
      " 10  has_washer_dryer  3539 non-null   int64  \n",
      " 11  has_doorman       3539 non-null   int64  \n",
      " 12  has_elevator      3539 non-null   int64  \n",
      " 13  has_dishwasher    3539 non-null   int64  \n",
      " 14  has_patio         3539 non-null   int64  \n",
      " 15  has_gym           3539 non-null   int64  \n",
      " 16  neighborhood      3539 non-null   object \n",
      " 17  borough           3539 non-null   object \n",
      "dtypes: float64(2), int64(14), object(2)\n",
      "memory usage: 497.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the 3,539 instances boasts these features along with others (rental properties) and a target (rent rate). Qualitative concerns relating to not a number occurences can thus be dismissed. Present occurrences demonstrate further meaningful data typing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rental_id</th>\n",
       "      <th>rent</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>size_sqft</th>\n",
       "      <th>min_to_subway</th>\n",
       "      <th>floor</th>\n",
       "      <th>building_age_yrs</th>\n",
       "      <th>no_fee</th>\n",
       "      <th>has_roofdeck</th>\n",
       "      <th>has_washer_dryer</th>\n",
       "      <th>has_doorman</th>\n",
       "      <th>has_elevator</th>\n",
       "      <th>has_dishwasher</th>\n",
       "      <th>has_patio</th>\n",
       "      <th>has_gym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5332.589997</td>\n",
       "      <td>5138.940379</td>\n",
       "      <td>1.351936</td>\n",
       "      <td>1.366770</td>\n",
       "      <td>939.727324</td>\n",
       "      <td>4.970896</td>\n",
       "      <td>11.908307</td>\n",
       "      <td>51.994914</td>\n",
       "      <td>0.403504</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>0.160215</td>\n",
       "      <td>0.281153</td>\n",
       "      <td>0.294716</td>\n",
       "      <td>0.185646</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>0.174908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3311.552136</td>\n",
       "      <td>3162.824760</td>\n",
       "      <td>0.967595</td>\n",
       "      <td>0.599588</td>\n",
       "      <td>477.949074</td>\n",
       "      <td>5.513589</td>\n",
       "      <td>10.960893</td>\n",
       "      <td>39.380433</td>\n",
       "      <td>0.490669</td>\n",
       "      <td>0.361809</td>\n",
       "      <td>0.366857</td>\n",
       "      <td>0.449625</td>\n",
       "      <td>0.455979</td>\n",
       "      <td>0.388875</td>\n",
       "      <td>0.228208</td>\n",
       "      <td>0.379942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2443.500000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>613.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5128.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8149.500000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1141.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11349.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4800.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rental_id          rent  bedrooms  bathrooms    size_sqft   \n",
       "mean   5332.589997   5138.940379  1.351936   1.366770   939.727324  \\\n",
       "std    3311.552136   3162.824760  0.967595   0.599588   477.949074   \n",
       "min       1.000000   1300.000000  0.000000   0.000000   250.000000   \n",
       "25%    2443.500000   3150.000000  1.000000   1.000000   613.000000   \n",
       "50%    5128.000000   4000.000000  1.000000   1.000000   800.000000   \n",
       "75%    8149.500000   6000.000000  2.000000   2.000000  1141.000000   \n",
       "max   11349.000000  20000.000000  5.000000   5.000000  4800.000000   \n",
       "\n",
       "      min_to_subway      floor  building_age_yrs    no_fee  has_roofdeck   \n",
       "mean       4.970896  11.908307         51.994914  0.403504      0.154846  \\\n",
       "std        5.513589  10.960893         39.380433  0.490669      0.361809   \n",
       "min        0.000000   0.000000          0.000000  0.000000      0.000000   \n",
       "25%        2.000000   4.000000         15.000000  0.000000      0.000000   \n",
       "50%        4.000000   8.000000         39.000000  0.000000      0.000000   \n",
       "75%        6.000000  17.000000         90.000000  1.000000      0.000000   \n",
       "max       43.000000  83.000000        180.000000  1.000000      1.000000   \n",
       "\n",
       "      has_washer_dryer  has_doorman  has_elevator  has_dishwasher  has_patio   \n",
       "mean          0.160215     0.281153      0.294716        0.185646   0.055100  \\\n",
       "std           0.366857     0.449625      0.455979        0.388875   0.228208   \n",
       "min           0.000000     0.000000      0.000000        0.000000   0.000000   \n",
       "25%           0.000000     0.000000      0.000000        0.000000   0.000000   \n",
       "50%           0.000000     0.000000      0.000000        0.000000   0.000000   \n",
       "75%           0.000000     1.000000      1.000000        0.000000   0.000000   \n",
       "max           1.000000     1.000000      1.000000        1.000000   1.000000   \n",
       "\n",
       "       has_gym  \n",
       "mean  0.174908  \n",
       "std   0.379942  \n",
       "min   0.000000  \n",
       "25%   0.000000  \n",
       "50%   0.000000  \n",
       "75%   0.000000  \n",
       "max   1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().iloc[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions of occurrences suggest the presence of outliers, particularly in features such as **_bedrooms_**, **_bathrooms_**, **_size_sqft_**, **_min_to_subway_**, and **_floor_**, as well as in the target (**_rent_**). As notably, both the minimum and the three quartiles tend to be closely situated as compared to the maximum. Outlier density varies, tending to be greater as standard deviations approach means. Nearer these means are to the third quartile, the more extreme the trend. All other non-binary distributions fall within non-alarming ranges. Binary features do not prove overwhelmingly true, indicative of their discriminative power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 200%; text-align: center; border-radius: 10px 10px;\">Task 4 - EDA, Preprocessing</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter concerns the preprocessing of features and targets, in preparation for downstream baselines and neural networks. Preprocessing assumes further investigation at the granularity level of a feature or target, based in part on previously acquired evidence.\n",
    "\n",
    "Among these features, **_rental_id_**, **_neighborhood_**, and **_borough_** stood out. **_Rental_id_** and **_borough_** were to be discarded for their discriminatory power. Manhattan should, however, be verified as the only borough, so as not to contaminate, introducing noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for duplicate instances\n",
    "len(df[df.duplicated(keep = False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#check if single borough apparent\n",
    "print(df[\"borough\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\n",
    "    columns = [\n",
    "        \"rental_id\",\n",
    "        \"borough\"\n",
    "    ],\n",
    "    inplace = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumptions about a single borough are verified, giving rise to the drop. However, dropping should be performed following a duplicate instance check. A critical step, as duplicates falsely emphasize patterns, introducing bias. Yet no duplicates exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighborhood\n",
       "Upper West Side        579\n",
       "Upper East Side        500\n",
       "Midtown East           460\n",
       "Midtown West           314\n",
       "Financial District     268\n",
       "Chelsea                182\n",
       "Flatiron               132\n",
       "Midtown                119\n",
       "Tribeca                119\n",
       "East Village           108\n",
       "Battery Park City      104\n",
       "Midtown South           85\n",
       "Central Harlem          82\n",
       "West Village            67\n",
       "Greenwich Village       66\n",
       "Gramercy Park           61\n",
       "Soho                    58\n",
       "Washington Heights      54\n",
       "East Harlem             41\n",
       "Lower East Side         41\n",
       "Central Park South      23\n",
       "Hamilton Heights        16\n",
       "Morningside Heights     13\n",
       "Inwood                  12\n",
       "Nolita                   9\n",
       "Chinatown                8\n",
       "Roosevelt Island         5\n",
       "Long Island City         4\n",
       "Stuyvesant Town/PCV      3\n",
       "Little Italy             3\n",
       "West Harlem              2\n",
       "Manhattanville           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"neighborhood\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While rare occurrences were probable to arise in neighborhoods, as validated by a check. Those should be treated as a measure of downstream split representativeness. In doing so grasp of variations shall be balanced with discriminatory power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df[df[\"neighborhood\"] != \"Long Island City\"]\n",
    "      .replace(\n",
    "          to_replace = {\n",
    "              \"Battery Park City\": \"community_board_1\",\n",
    "              \"Financial District\": \"community_board_1\",\n",
    "              \"Tribeca\": \"community_board_1\",\n",
    "              \"Greenwich Village\": \"community_board_2\",\n",
    "              \"Little Italy\": \"community_board_2\",\n",
    "              \"Nolita\": \"community_board_2\",\n",
    "              \"Soho\": \"community_board_2\",\n",
    "              \"West Village\": \"community_board_2\",\n",
    "              \"Chinatown\": \"community_board_3\",\n",
    "              \"East Village\": \"community_board_3\",\n",
    "              \"Lower East Side\": \"community_board_3\",\n",
    "              \"Chelsea\": \"community_board_4\",\n",
    "              \"Midtown West\": \"community_board_4\",\n",
    "              \"Central Park South\": \"community_board_5\",\n",
    "              \"Flatiron\": \"community_board_5\",\n",
    "              \"Midtown\": \"community_board_5\",\n",
    "              \"Midtown South\": \"community_board_5\",\n",
    "              \"Gramercy Park\": \"community_board_6\",\n",
    "              \"Midtown East\": \"community_board_6\",\n",
    "              \"Stuyvesant Town/PCV\": \"community_board_6\",\n",
    "              \"Upper West Side\": \"community_board_7\",\n",
    "              \"Upper East Side\": \"community_board_8\",\n",
    "              \"Roosevelt Island\": \"community_board_8\",\n",
    "              \"Hamilton Heights\": \"community_board_9\",\n",
    "              \"Manhattanville\": \"community_board_9\",\n",
    "              \"Morningside Heights\": \"community_board_9\",\n",
    "              \"West Harlem\": \"community_board_9\",\n",
    "              \"Central Harlem\": \"community_board_10\",\n",
    "              \"East Harlem\": \"community_board_11\",\n",
    "              \"Inwood\": \"community_board_12\",\n",
    "              \"Washington Heights\": \"community_board_12\"\n",
    "          }\n",
    "      )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Community boards, sharing advisory roles in areas such as city budgets or municipal service delivery, allow for such a balance. Neighborhoods are, therefore, relegated in granularity to community boards. With Long Island City specifically excluded due to its affiliation with Queens, causing noise prior mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x3000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "title = \"Boxplots on Feature Distribution\"\n",
    "\n",
    "feats = [\n",
    "    df[[\"bedrooms\", \"bathrooms\"]], \n",
    "    df[[\"size_sqft\"]], \n",
    "    df[[\"min_to_subway\"]],\n",
    "    df[[\"floor\"]],\n",
    "    df[[\"building_age_yrs\"]],\n",
    "    df[[\"rent\"]]\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    \"Rooms\",\n",
    "    \"Square Feet\",\n",
    "    \"Minutes\",\n",
    "    \"Floor\",\n",
    "    \"Years\",\n",
    "    \"US Dollar\"\n",
    "]\n",
    "\n",
    "num = len(feats)\n",
    "fig, axs = plt.subplots(nrows = num, \n",
    "                        ncols = 1, \n",
    "                        figsize = (8, (num * 5)))\n",
    "for ax, feat, label in zip(axs, feats, labels):\n",
    "    ax.boxplot(\n",
    "        x = feat,\n",
    "        labels = feat.columns,\n",
    "        patch_artist = True,\n",
    "        boxprops = dict(\n",
    "            facecolor = \"#dcf6ff\",\n",
    "            edgecolor = \"#032765\"\n",
    "        ),\n",
    "        capprops = dict(\n",
    "            color = \"#032765\"\n",
    "        ),\n",
    "        flierprops = dict(\n",
    "            markerfacecolor = \"#ff0f0f\",\n",
    "            markeredgecolor = \"#ff0f0f\"\n",
    "        ),\n",
    "        medianprops = dict(\n",
    "            color = \"#ff0f0f\"\n",
    "        ),\n",
    "        whiskerprops = dict(\n",
    "            color = \"#032765\"\n",
    "        )\n",
    "    );\n",
    "    ax.set_ylabel(ylabel = label);\n",
    "fig.suptitle(t = title,\n",
    "             y = 0.9);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous features and target on the other hand raised suspicions regarding outlier affections. Assumptions ascribed seem valid in light of the boxplots presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">rent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3299</td>\n",
       "      <td>3308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1600</td>\n",
       "      <td>1790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2595</td>\n",
       "      <td>2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2600</td>\n",
       "      <td>2650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3999</td>\n",
       "      <td>4400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7495</td>\n",
       "      <td>7795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3340</td>\n",
       "      <td>3545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2595</td>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3400</td>\n",
       "      <td>3650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3150</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7500</td>\n",
       "      <td>8150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4900</td>\n",
       "      <td>4950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2495</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2700</td>\n",
       "      <td>2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5995</td>\n",
       "      <td>6495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7995</td>\n",
       "      <td>8995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4795</td>\n",
       "      <td>5295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>6200</td>\n",
       "      <td>6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>14950</td>\n",
       "      <td>17000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rent       \n",
       "      min    max\n",
       "1    3299   3308\n",
       "8    1600   1790\n",
       "9    2595   2750\n",
       "10   2600   2650\n",
       "11   3999   4400\n",
       "13   7495   7795\n",
       "15   3340   3545\n",
       "16   2595   2600\n",
       "18   3400   3650\n",
       "19   3150   3300\n",
       "23   7500   8150\n",
       "24   4900   4950\n",
       "25   2495   2500\n",
       "27   2700   2750\n",
       "28   5995   6495\n",
       "30   7995   8995\n",
       "31   4795   5295\n",
       "38   6200   6400\n",
       "39  14950  17000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = df.iloc[:, 1:]\n",
    "df_dup = (df.loc[feats[feats.duplicated(keep = False)].index]\n",
    "          .groupby(\n",
    "              by = list(\n",
    "                  feats.columns\n",
    "              )\n",
    "          )\n",
    "          .agg(\n",
    "              func = {\n",
    "                  \"rent\": [\"min\", \"max\"]\n",
    "              }\n",
    "          )\n",
    "          .reset_index(\n",
    "              drop = True \n",
    "          )\n",
    ")\n",
    "df_dup[(df_dup[(\"rent\", \"min\")] != df_dup[(\"rent\", \"max\")])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An outlier, sharing a conflicting duplicate with a non-outlier, would cause downstream struggle. Struggle, as in attempts to minimize overall error, leading to compromises not fair to either end. Given the foregoing context, contradictory duplicates should be sought. By doing so, 19 contradictory duplicate groups were found. However, all of them pose insignificant variations, allowing regressor coping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tars = df.loc[:, [\"rent\"]]\n",
    "feats = df.drop(\"rent\", \n",
    "                axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessed features and target are subsequently separated to be split downstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    feats, \n",
    "    tars, \n",
    "    test_size = 0.2, \n",
    "    shuffle = True, \n",
    "    stratify = feats[\"neighborhood\"], \n",
    "    random_state = random_state\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, \n",
    "    y_train_full, \n",
    "    test_size = 0.25, \n",
    "    shuffle = True, \n",
    "    stratify = X_train_full[\"neighborhood\"],\n",
    "    random_state = random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting is performed as evaluation of a model should not be conducted with the same data as training. By evaluating based on training data, data is more likely to be memorized rather than capturing underlying patterns. Memorization comes at the expense of generalizability to unseen data, leading to overfitting. \n",
    "\n",
    "Deep learning involves two instances of evaluation. First, evaluation for determination of training's optimal state. Secondly, evaluation of the optimal state, as data leakage occurs due to the determination described.\n",
    "\n",
    "As part of the hyperparameters, shuffle was enabled to mitigate potential order bias, which may be introduced by the original order of instances. The split of 60% training, 20% validation, and 20% test was chosen. 3,539 instances drive such decision, necessitating greater proportions of training required to capture patterns, with sufficient evaluation sizes to ensure reliable quality. \n",
    "\n",
    "Further consideration should be given to the community boards, encapsulating a range of factors, justifying premiums or concessions. The way to ensure fair representation is by stratification, preventing undercoverage bias.\n",
    "\n",
    "Split scaling is imperative for linear regression and neural networks. Given the sensitivity of the underlying optimizations to feature magnitudes. Sensitively, as greater magnitude coincides with stronger weight implications. Models with large weights tend to be unstable, causing poor learning performance and higher generalization errors. Large weights may also result from high error gradients caused by the target magnitude in neural networks, assuming its scaling. As a step towards scaler selection, features are further tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>sw_test</th>\n",
       "      <th>ks_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bedrooms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bathrooms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>size_sqft</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>min_to_subway</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>floor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>building_age_yrs</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  sw_test  ks_test\n",
       "0              rent      0.0      0.0\n",
       "1          bedrooms      0.0      0.0\n",
       "2         bathrooms      0.0      0.0\n",
       "3         size_sqft      0.0      0.0\n",
       "4     min_to_subway      0.0      0.0\n",
       "5             floor      0.0      0.0\n",
       "6  building_age_yrs      0.0      0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_lim = 10\n",
    "pd.DataFrame(data = [\n",
    "    {\n",
    "        \"feature\": feat,\n",
    "        \"sw_test\": np.round(\n",
    "            stats.shapiro(x = df[feat])[1], \n",
    "            round_lim\n",
    "        ),\n",
    "        \"ks_test\": np.round(\n",
    "            stats.kstest(rvs = df[feat], cdf = \"norm\")[1], \n",
    "            round_lim\n",
    "        )\n",
    "    }\n",
    "    for feat in df.iloc[:, :7]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution curves of features are therefore evaluated for Gaussian shape adherence. Indications of Gaussian distributions are drawn by the Shapiro-Wilk and Kolmogorow-Smirnow tests. Binary features are omitted within those tests, as Gaussian constitutes a continuous distribution probability. Tests yield p-values close to zero, well below the significance level of 0.05. Gaussian distribution appears thus unlikely.\n",
    "\n",
    "Standard scalers assume, however, such Gaussian distributions. As a consequence, underlying z-scores may be miscentering, causing potential significance bias. Min-max scalers are, by contrast, prone to outliers due to their direct influence. Thus, an outlier may raise the maximum, narrowing majorities, which causes information loss. Those conditions favor the robust scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preparation():\n",
    "    def __init__(self, feats_dfs, tars_dfs, scaler):\n",
    "        self.feats_dfs = feats_dfs\n",
    "        self.tars_dfs = tars_dfs\n",
    "        self.scaler = scaler\n",
    "\n",
    "    #initialize scaler\n",
    "    def init_scaler(self, df):\n",
    "        scaler = self.scaler\n",
    "        return scaler.fit(df)\n",
    "\n",
    "    #dummy encode input\n",
    "    def dummify(self, df, dmy_cols):\n",
    "        return pd.get_dummies(\n",
    "            data = df,\n",
    "            columns = dmy_cols,\n",
    "            drop_first = True,\n",
    "            dtype = int\n",
    "        )\n",
    "    \n",
    "    #cast scaled input to tensor\n",
    "    def transform(self, df, scaler):\n",
    "        return torch.Tensor(scaler.transform(df))\n",
    "    \n",
    "    #dummify, scale, and transform features\n",
    "    def prep_feats(self, fit_index, dmy_cols):\n",
    "        self.feats_scaler = self.init_scaler(\n",
    "            self.dummify(self.feats_dfs[fit_index], dmy_cols)\n",
    "        )\n",
    "        self.feats = [\n",
    "            self.transform(self.dummify(df, dmy_cols), self.feats_scaler)\n",
    "            for df in self.feats_dfs\n",
    "        ]\n",
    "    \n",
    "    #scale and transform targets\n",
    "    def prep_tars(self, fit_index):\n",
    "        self.tars_scaler = self.init_scaler(self.tars_dfs[fit_index])\n",
    "        self.tars = [\n",
    "            self.transform(df, self.tars_scaler)\n",
    "            for df in self.tars_dfs\n",
    "        ]\n",
    "    \n",
    "feats_dfs = [\n",
    "    X_train_full,\n",
    "    X_train,\n",
    "    X_val,\n",
    "    X_test\n",
    "]\n",
    "\n",
    "tars_dfs = [\n",
    "    y_train_full,\n",
    "    y_train,\n",
    "    y_val,\n",
    "    y_test\n",
    "]\n",
    "\n",
    "prep = preparation(feats_dfs, tars_dfs, RobustScaler())\n",
    "\n",
    "def prep_wrapper(fit_index):\n",
    "    prep.prep_feats(fit_index, [\"neighborhood\"])\n",
    "    prep.prep_tars(fit_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature scaling requires **_neighborhood_** treatment, performed at a downstream stage to allow stratification. Community boards within **_neighborhood_** are largely independent, suggesting dummy encoding. Once encoded, scaling can take place. Scalers themselves are fitted on training and validation data for features and targets, respectively. Test data is deliberately excluded to prevent data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 200%; text-align: center; border-radius: 10px 10px;\">Task 5 - Baselines</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baselines are explored in the following chapter, as a reference for sanity in later, more complex approaches. Such baselines are rooted in dummy and simple machine learning models, built on previously preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_wrapper(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is crucial to note that the preprocessed data's scaler exclusively fits on the training partition. As the validation partition does not actively engage in training, introducing data leakage at no value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict target based on dummy regressor\n",
    "def dmy_preds(reg_dmy, ptns_feats):\n",
    "    return [\n",
    "        (\n",
    "            torch.Tensor(\n",
    "                reg_dmy.predict(X = ptn_feats)\n",
    "            )\n",
    "            .unsqueeze(1)\n",
    "        )\n",
    "        for ptn_feats in ptns_feats\n",
    "    ]\n",
    "\n",
    "#construct and train dummy regressor\n",
    "dmy_baseline = (\n",
    "    DummyRegressor(\n",
    "        strategy = \"median\"\n",
    "    )\n",
    "    .fit(prep.feats[1], y_train)\n",
    ")\n",
    "\n",
    "dmy__preds = dmy_preds(dmy_baseline, prep.feats[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaled data serves first the most basic baseline of a dummy regressor. Strategy choice for such regressor is driven by outliers and their impact on the central tendency, suggesting median. Medians establish robustness, as opposed to outlier-skewed means. As the median depends upon the targets, feature scaling has no bearing, negating additional preparation efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict target based on ml regressor\n",
    "def ml_preds(reg_ml, ptns_feats):\n",
    "    return [\n",
    "        reg_ml.predict(ptn_feats)\n",
    "        for ptn_feats in ptns_feats\n",
    "    ]\n",
    "\n",
    "#construct and train linear regressor\n",
    "ml_baseline = (\n",
    "    LinearRegression()\n",
    "    .fit(\n",
    "        X = prep.feats[1],\n",
    "        y = y_train\n",
    "    )\n",
    ")\n",
    "\n",
    "ml__preds = ml_preds(ml_baseline, prep.feats[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression serves as the machine learning counterpart to the dummy regressor. Particularly, this algorithm for its simplicity, often regarded as industry standard for regression baselines. Those baselines constitute predictions. Assumed predictions are emitted for training, validation and testing according to both approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 200%; text-align: center; border-radius: 10px 10px;\">Task 6 - Deep Learning Experiments</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter delves into the exploration of neural networks as rental rate estimators. By doing so, architecture spectrums are investigated, guiding hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(torch.nn.Module):\n",
    "    def __init__(self, layers, activation):\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "        self.hidden_layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                torch.nn.Linear(*layer)\n",
    "                for layer in layers\n",
    "            ]\n",
    "        )\n",
    "        self.activation = activation\n",
    "    \n",
    "    #predict target based on neural network\n",
    "    def forward(self, ptn_feats):\n",
    "        for layer in self.hidden_layers[:-1]:\n",
    "            ptn_feats = self.activation(layer(ptn_feats))\n",
    "        return self.hidden_layers[-1](ptn_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture refers to the composition of a multilayer perceptron. Composition may vary across layers, neurons, and activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_trainer():\n",
    "\n",
    "    ########################################################################################################################\n",
    "    #initialize class attributes\n",
    "    ########################################################################################################################\n",
    "\n",
    "    #partitions and reproducibility\n",
    "    def __init__(self, X_train_full, X_train, X_val, y_train_full, y_train, y_val, y_scaler):\n",
    "        self.X_train_full = X_train_full\n",
    "        self.X_train = X_train\n",
    "        self.X_val = X_val\n",
    "        self.y_train_full = y_train_full\n",
    "        self.y_train = y_train\n",
    "        self.y_val = y_val\n",
    "        self.y_scaler = y_scaler\n",
    "\n",
    "        self.random_state = 42\n",
    "\n",
    "    #reproducibility\n",
    "    def init_seeds(self):\n",
    "        random.seed(42)\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "    #hyperparameters\n",
    "    def init_hparms(self, criterion, es_threshold, es_patience, opt_eval, train_eval, learning_rate, max_epochs, optimizer):\n",
    "        self.init_seeds()\n",
    "        self.criterion = criterion\n",
    "        self.es_threshold = es_threshold\n",
    "        self.es_patience = es_patience\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_epochs = max_epochs\n",
    "        self.train_eval = train_eval\n",
    "        self.optimizer = optimizer\n",
    "        self.opt_eval = opt_eval\n",
    "\n",
    "    #update class attributes\n",
    "    def updt_hparms(self, **kwargs):\n",
    "        self.init_seeds()\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "\n",
    "    ########################################################################################################################\n",
    "    #shortcuts\n",
    "    ########################################################################################################################\n",
    "\n",
    "    #display table row\n",
    "    def print_row(self, data_points, spaces):\n",
    "        return \"\".join(\n",
    "            f\"|{data_point:^{space}}|\" \n",
    "            for data_point, space in zip(data_points, spaces)\n",
    "        )\n",
    "\n",
    "    #display grid lines\n",
    "    def print_seps(self, seps):\n",
    "        return \"-\" * seps\n",
    "    \n",
    "    #deepcopy neural network\n",
    "    def copy_model(self, model):\n",
    "        return copy.deepcopy(model.state_dict())\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "\n",
    "    ########################################################################################################################\n",
    "    #compute estimation\n",
    "    ########################################################################################################################\n",
    "\n",
    "    #estimate loss metric\n",
    "    def preds_loss(self, model, ptn_feats, ptn_tars):\n",
    "        ptn_preds = model(ptn_feats)\n",
    "        return ptn_preds, self.criterion(\n",
    "            ptn_preds,\n",
    "            ptn_tars\n",
    "        )\n",
    "    \n",
    "    #unscale estimations\n",
    "    def inv_preds(self, ptn_preds, scaler):\n",
    "        return [\n",
    "            scaler.inverse_transform(X = ptn_pred)\n",
    "            for ptn_pred in ptn_preds\n",
    "        ]\n",
    "    \n",
    "    #estimate evaluation metric (e.g., MAPE)\n",
    "    def preds_eval(self, ptn_tars, ptn_preds):\n",
    "        return self.train_eval(\n",
    "            *self.inv_preds(\n",
    "                [ptn_tars, ptn_preds],\n",
    "                self.y_scaler\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    #estimate target\n",
    "    def dl_preds(self, model, ptns_feats):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            return [\n",
    "                model(ptn_feats)\n",
    "                for ptn_feats in ptns_feats\n",
    "            ]\n",
    "        \n",
    "    ########################################################################################################################\n",
    "\n",
    "\n",
    "    ########################################################################################################################\n",
    "    #train neural network\n",
    "    ########################################################################################################################\n",
    "\n",
    "    def train(self, identifier, model, worst_loss, worst_eval, round_lim):\n",
    "\n",
    "        #intitialize default\n",
    "        self.init_seeds()\n",
    "        optimizer = self.optimizer(\n",
    "            params = model.parameters(),\n",
    "            lr = self.learning_rate\n",
    "        )\n",
    "        es_epoch, es_patience, es_loss = 0, 0, worst_loss\n",
    "        self.best_model = self.copy_model(model)\n",
    "        self.best_epoch = 0\n",
    "        self.best_loss, self.best_eval = worst_loss, worst_eval\n",
    "        ####################################################################################################################\n",
    "\n",
    "        writer = SummaryWriter()\n",
    "\n",
    "        #display table head \n",
    "        mtrc_size = np.round(random.random(), round_lim)\n",
    "        col_names = [\n",
    "            \"Epoch\", \n",
    "            \"Training Loss\", \n",
    "            \"Validation Loss\", \n",
    "            \"Training Evaluation\", \n",
    "            \"Validation Evaluation\"\n",
    "        ]\n",
    "        spaces = [\n",
    "            max(\n",
    "                [\n",
    "                    len(str(ptn_arg))\n",
    "                    for ptn_arg in ptn_args\n",
    "                ]\n",
    "            ) + 2\n",
    "            for ptn_args in [\n",
    "                 [col_names[0], self.max_epochs],\n",
    "                 *[\n",
    "                      [\n",
    "                           ptn_arg, mtrc_size\n",
    "                      ]\n",
    "                      for ptn_arg in col_names[1:]\n",
    "                 ]\n",
    "            ]\n",
    "        ]\n",
    "        seps = sum(spaces) + 2 * len(spaces)\n",
    "        head = [\n",
    "            self.print_seps(seps), \n",
    "            f\"|{identifier:^{seps - 2}}|\", \n",
    "            self.print_seps(seps), \n",
    "            self.print_row(col_names, spaces), \n",
    "            self.print_seps(seps)\n",
    "        ]\n",
    "        for function in head:\n",
    "            print(function)\n",
    "        ####################################################################################################################\n",
    "\n",
    "        #optimize\n",
    "        while (es_epoch := es_epoch + 1) < self.max_epochs and (es_patience := es_patience + 1) <= self.es_patience:\n",
    "            model.train()\n",
    "            _, train_loss = self.preds_loss(\n",
    "                model, self.X_train, self.y_train\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        ####################################################################################################################\n",
    "\n",
    "            #judge optimization\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_train_preds, train_loss = self.preds_loss(\n",
    "                    model, self.X_train, self.y_train\n",
    "                )\n",
    "                y_val_preds, val_loss = self.preds_loss(\n",
    "                    model, self.X_val, self.y_val\n",
    "                )\n",
    "                writer.add_scalars(\n",
    "                    \"experiments_loss\",\n",
    "                    {\"train\": train_loss.item(),\n",
    "                     \"val\": val_loss.item()},\n",
    "                    es_epoch\n",
    "                ) \n",
    "                train_eval = self.preds_eval(\n",
    "                    self.y_train, y_train_preds\n",
    "                )\n",
    "                val_eval = self.preds_eval(\n",
    "                    self.y_val, y_val_preds\n",
    "                )\n",
    "                writer.add_scalars(\n",
    "                    \"experiments_eval\", \n",
    "                    {\"train\": train_eval,\n",
    "                     \"val\": val_eval},\n",
    "                    es_epoch\n",
    "                ) \n",
    "                writer.flush()\n",
    "\n",
    "                #store best optimal state\n",
    "                if val_eval < self.best_eval:\n",
    "                    self.best_model = self.copy_model(model)\n",
    "                    self.best_epoch = es_epoch\n",
    "                    self.best_loss, self.best_eval = val_loss.item(), val_eval\n",
    "\n",
    "                #patience counter reset\n",
    "                if val_loss + self.es_threshold < es_loss:\n",
    "                    es_loss, es_patience = val_loss, 0\n",
    "            ################################################################################################################\n",
    "\n",
    "        #display training progress\n",
    "            if es_epoch == 1 or es_epoch % 10 == 0:\n",
    "                data_points = [\n",
    "                    es_epoch,\n",
    "                    *[\n",
    "                        np.round(ptn_mtrc, round_lim)\n",
    "                        for ptn_mtrc in [\n",
    "                            train_loss.item(),\n",
    "                            val_loss.item(),\n",
    "                            train_eval,\n",
    "                            val_eval\n",
    "                        ]\n",
    "                    ]\n",
    "                ]\n",
    "                print(self.print_row(data_points, spaces))\n",
    "        print(self.print_seps(seps))\n",
    "        ####################################################################################################################\n",
    "\n",
    "        writer.close()\n",
    "\n",
    "    ########################################################################################################################\n",
    "        \n",
    "\n",
    "    ########################################################################################################################\n",
    "    #optimize neural network\n",
    "    ########################################################################################################################\n",
    "        \n",
    "    #construct estimator\n",
    "    def init_estimator(self, estimator, dflt_lays, dflt_act):\n",
    "        self.estimator =  NeuralNetRegressor(\n",
    "            module = estimator,\n",
    "            module__layers = dflt_lays,\n",
    "            module__activation = dflt_act,\n",
    "            criterion = self.criterion,\n",
    "            optimizer = self.optimizer,\n",
    "            lr = self.learning_rate,\n",
    "            max_epochs = self.max_epochs,\n",
    "            batch_size = -1,\n",
    "            train_split = None,\n",
    "            predict_nonlinearity = None,\n",
    "            verbose = 0\n",
    "        )\n",
    "\n",
    "    #identify best hyperparameters\n",
    "    def optimize(self, grid, splts, reps):\n",
    "\n",
    "        #setup cross validated grid search\n",
    "        self.reg = GridSearchCV(\n",
    "            estimator = self.estimator,\n",
    "            param_grid = grid,\n",
    "            scoring = self.opt_eval,\n",
    "            n_jobs = -1,\n",
    "            refit = True,\n",
    "            cv = RepeatedKFold(\n",
    "                n_splits = splts,\n",
    "                n_repeats = reps,\n",
    "                random_state = self.random_state\n",
    "            ),\n",
    "            verbose = 1\n",
    "        )\n",
    "\n",
    "        #intitialize cross validated grid search\n",
    "        self.reg.fit(\n",
    "            X = self.X_train_full,\n",
    "            y = self.y_train_full\n",
    "        )\n",
    "    \n",
    "    ########################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a multilayer perceptron is trained, neuron weights and biases are optimized. Optimization relies on the Adam optimizer, the industry's go-to. The go-to, owing to its stabilizing correction of initialization bias, coupled with dynamic learning rates at each parameter. Its application occurs across numerous epochs, here 1000 as a common default. 1000 to presumably permit ample room for optimization. Such room exhaustion is regulated via early stoppage, for the sake of runtime. Early stoppage triggered by validation loss following a period of insufficient improvement. The period under consideration is defined by patience at a default setting of five, striking an assumed balance between premature stoppage and time spent on plateus. Insufficient improvement within those periods is equated to an absence of improvement, due to reasonable computational overhead being expected. Improvement as measured by a mean absolute error _(L1)_ loss criterion. Mean squared error _(MSE)_ was deemed inequitable, due to outlier sensitivity. In light of the fact that greater errors are penalized with greater losses, minimized by the optimizer, resulting in outlier bias. Loss measured in validation as optimized based on training, with overfitting eventually taking precedence at the expense of runtime. Optimization based on training entails several steps. First, a forward pass is performed, yielding predictions, compared to a ground truth manifested in loss. Gradients are then computed and accumulated by back propagation, the more efficient counterpart to forward propagation. Final optimization is rooted in those accumulated gradients, presuming the erasure of those prior to the current epoch. For optimization purposes, each loss and evaluation begins with an infinity value. Infinity as to gurantee capture of virtually every initial encounter as improvement. The optimal state is determined by the mean absolute percentage error _(MAPE)_. As _MAPE_ gauges diverse target groups. Considering that, deviations among target groups with lower budgets may be small in absolute terms, yet still relevant, given the global stimulation intentions of landlord-tenant interactions. During evaluation, multilayer perceptron mode shall be set to eval, accounting for potential differences in behaviors. At present, no action would be required, however in anticipation of multilayer perceptron changes. In this sense, optimization also takes place in train mode. All metrics accumulated after optimization are written to the tensorboard for live monitoring, allowing early detection of problems during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_wrapper(0)\n",
    "trainer = model_trainer(\n",
    "    *prep.feats[:-1],\n",
    "    *prep.tars[:-1],\n",
    "    prep.tars_scaler\n",
    ")\n",
    "\n",
    "trainer.init_hparms(\n",
    "    criterion = torch.nn.L1Loss(),\n",
    "    es_threshold = 0,\n",
    "    es_patience = 5,\n",
    "    opt_eval = \"\",\n",
    "    train_eval = mean_absolute_percentage_error,  \n",
    "    learning_rate = 0.01, \n",
    "    max_epochs = 1000,\n",
    "    optimizer = torch.optim.Adam, \n",
    ")\n",
    "\n",
    "def model_trainer_wrapper(identifier, layers, activation):\n",
    "\n",
    "    #construct neural network\n",
    "    model = MultiLayerPerceptron(\n",
    "        layers = layers, \n",
    "        activation = activation\n",
    "    )\n",
    "\n",
    "    #train neural network\n",
    "    trainer.train(\n",
    "        identifier = identifier,\n",
    "        model = model,\n",
    "        worst_eval = float(\"inf\"),\n",
    "        worst_loss = float(\"inf\"),\n",
    "        round_lim = 8\n",
    "    )\n",
    "\n",
    "    #retrieve best neural network\n",
    "    model.load_state_dict(trainer.best_model)\n",
    "\n",
    "    #estimate predictions\n",
    "    return trainer.inv_preds(\n",
    "        trainer.dl_preds(\n",
    "            model, \n",
    "            prep.feats[1:]\n",
    "        ), \n",
    "        prep.tars_scaler\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given time limitations, training sessions cannot grasp the full breadth of architecture variations. The focus of investigation lies thus on width, i.e. the amount of neurons per layer as well as activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 150%; text-align: center; border-radius: 10px 10px;\">6.1 - Architectural Exploration</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among those activation functions, hard hyperbolic tangent _(HardTanh)_ and parametric rectified linear unit _(PReLU)_ are considered, due to their state-of-the-art efficiency. State-of-the-art efficiency for mitigating vanishing gradients, in back propagation from output to early layers, otherwise causing slow convergence, stalled networks, and impaired learning. Moreover, _PReLU_ over rectified linear unit _(ReLU)_, as negative neuronal inputs would otherwise inhibit gradient flow and therefore tuning, resulting in inactive neurons and thus loss of capacity. Treatment of these negative neuronal inputs can be tuned in _PReLU_, as opposed to leaky _ReLU_, favoring it for its adaptability. In both cases, a default is assumed in the interim, to be tuned in the later grid search. Layer's default hyperparameters are informed by experience (lectures). Based on that default, widths are investigated by a factor of two, beginning with _PReLU_, proceeding to _HardTanh_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------\n",
      "|                                       Narrow PReLU                                        |\n",
      "---------------------------------------------------------------------------------------------\n",
      "| Epoch || Training Loss || Validation Loss || Training Evaluation || Validation Evaluation |\n",
      "---------------------------------------------------------------------------------------------\n",
      "|   1   ||  0.70574725   ||   0.61314946    ||     0.33248287      ||      0.30859767       |\n",
      "|  10   ||   0.347298    ||   0.32914948    ||     0.18624706      ||      0.18904929       |\n",
      "|  20   ||  0.29245612   ||   0.28144911    ||     0.15398119      ||      0.15773289       |\n",
      "|  30   ||   0.2627556   ||   0.25270161    ||     0.13197769      ||      0.13326843       |\n",
      "|  40   ||   0.2532059   ||   0.25057566    ||     0.12573963      ||      0.13057864       |\n",
      "|  50   ||  0.24458393   ||   0.24907269    ||     0.12191207      ||      0.13097418       |\n",
      "---------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dl__narrow_prelu_preds = model_trainer_wrapper(\n",
    "    \"Narrow PReLU\", \n",
    "    [[25, 64], [64, 32], [32, 16], [16, 1]], \n",
    "    torch.nn.PReLU()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------\n",
      "|                                       Default PReLU                                       |\n",
      "---------------------------------------------------------------------------------------------\n",
      "| Epoch || Training Loss || Validation Loss || Training Evaluation || Validation Evaluation |\n",
      "---------------------------------------------------------------------------------------------\n",
      "|   1   ||  0.66874629   ||   0.58228081    ||     0.32524447      ||      0.30273171       |\n",
      "|  10   ||  0.30781576   ||   0.28951862    ||     0.17447137      ||      0.17111044       |\n",
      "|  20   ||  0.26975238   ||   0.26465583    ||      0.1369607      ||      0.14079735       |\n",
      "|  30   ||  0.25206354   ||   0.25254083    ||     0.12624644      ||      0.13276176       |\n",
      "|  40   ||  0.23895925   ||   0.24608356    ||     0.12006744      ||      0.12968472       |\n",
      "|  50   ||  0.23285425   ||   0.24578363    ||     0.11339907      ||      0.12587863       |\n",
      "|  60   ||  0.22021998   ||   0.23983058    ||      0.1076402      ||       0.1224429       |\n",
      "|  70   ||  0.21046518   ||   0.24185769    ||     0.10359076      ||      0.12333204       |\n",
      "---------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dl__dflt_prelu_preds = model_trainer_wrapper(\n",
    "    \"Default PReLU\", \n",
    "    [[25, 128], [128, 64], [64, 32], [32, 1]], \n",
    "    torch.nn.PReLU(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------\n",
      "|                                        Wide PReLU                                         |\n",
      "---------------------------------------------------------------------------------------------\n",
      "| Epoch || Training Loss || Validation Loss || Training Evaluation || Validation Evaluation |\n",
      "---------------------------------------------------------------------------------------------\n",
      "|   1   ||  0.52117598   ||   0.45650834    ||     0.24876688      ||      0.23433749       |\n",
      "|  10   ||  0.28962299   ||   0.28025642    ||     0.14418581      ||      0.14766958       |\n",
      "|  20   ||   0.2779184   ||   0.26942307    ||     0.14879918      ||      0.15170251       |\n",
      "|  30   ||  0.25261319   ||   0.25083411    ||     0.13022005      ||      0.13528693       |\n",
      "|  40   ||  0.23803349   ||   0.24575205    ||      0.1174955      ||      0.12722456       |\n",
      "|  50   ||  0.22315067   ||   0.23807864    ||     0.11092297      ||      0.12369002       |\n",
      "|  60   ||  0.21379811   ||    0.235989     ||     0.10422396      ||       0.1207958       |\n",
      "|  70   ||  0.20388152   ||   0.23953632    ||     0.10227735      ||      0.12468161       |\n",
      "---------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dl__wide_prelu_preds = model_trainer_wrapper(\n",
    "    \"Wide PReLU\", \n",
    "    [[25, 256], [256, 128], [128, 64], [64, 1]], \n",
    "    torch.nn.PReLU()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_PReLU_ exhibits a trend across all metrics. The wider the network the better the initial fit of data. Yet, they tend to converge around similar regions over epochs, sharing a trajectory. Convergence occurs with narrowness over fewer epochs, preceding overfitting, as indicated by early stoppage. However, at roughly similar regions, as wider networks tend to slightly better fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------\n",
      "|                                      Narrow HardTanh                                      |\n",
      "---------------------------------------------------------------------------------------------\n",
      "| Epoch || Training Loss || Validation Loss || Training Evaluation || Validation Evaluation |\n",
      "---------------------------------------------------------------------------------------------\n",
      "|   1   ||  0.62225777   ||   0.54294771    ||     0.30886066      ||       0.2889148       |\n",
      "|  10   ||  0.35004848   ||   0.32048586    ||     0.18136666      ||      0.18310437       |\n",
      "|  20   ||  0.32035786   ||   0.28867251    ||     0.16600608      ||       0.1627378       |\n",
      "|  30   ||  0.30762932   ||   0.28169611    ||     0.15520717      ||      0.15491545       |\n",
      "|  40   ||  0.30067757   ||   0.27841082    ||      0.1556149      ||      0.15583897       |\n",
      "|  50   ||  0.29984319   ||   0.27839974    ||     0.15413679      ||      0.15430918       |\n",
      "---------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dl__narrow_hardtanh_preds = model_trainer_wrapper(\n",
    "    \"Narrow HardTanh\", \n",
    "    [[25, 64], [64, 32], [32, 16], [16, 1]], \n",
    "    torch.nn.Hardtanh()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------\n",
      "|                                     Default HardTanh                                      |\n",
      "---------------------------------------------------------------------------------------------\n",
      "| Epoch || Training Loss || Validation Loss || Training Evaluation || Validation Evaluation |\n",
      "---------------------------------------------------------------------------------------------\n",
      "|   1   ||  0.55853486   ||   0.50902694    ||     0.32768207      ||      0.31939273       |\n",
      "|  10   ||  0.34446383   ||   0.31114542    ||     0.18528446      ||      0.18127745       |\n",
      "|  20   ||  0.29713023   ||    0.2695685    ||     0.15433975      ||      0.15191596       |\n",
      "|  30   ||  0.32096162   ||   0.29984763    ||     0.18099359      ||      0.17834193       |\n",
      "---------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dl__dflt_hardtanh_preds = model_trainer_wrapper(\n",
    "    \"Default HardTanh\", \n",
    "    [[25, 128], [128, 64], [64, 32], [32, 1]], \n",
    "    torch.nn.Hardtanh()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------\n",
      "|                                       Wide HardTanh                                       |\n",
      "---------------------------------------------------------------------------------------------\n",
      "| Epoch || Training Loss || Validation Loss || Training Evaluation || Validation Evaluation |\n",
      "---------------------------------------------------------------------------------------------\n",
      "|   1   ||  0.62474877   ||   0.62830609    ||     0.43012628      ||      0.45201605       |\n",
      "|  10   ||  0.41870278   ||   0.37759063    ||      0.230443       ||      0.22465896       |\n",
      "|  20   ||  0.32697064   ||   0.29268822    ||     0.15359987      ||      0.15300004       |\n",
      "|  30   ||   0.2985267   ||   0.26837552    ||     0.15147467      ||      0.14782571       |\n",
      "|  40   ||  0.31548327   ||   0.30449334    ||     0.15902144      ||      0.16465182       |\n",
      "|  50   ||  0.28685111   ||   0.28054476    ||     0.13965849      ||      0.14679893       |\n",
      "|  60   ||  0.27112973   ||   0.26787794    ||     0.13161147      ||      0.13981652       |\n",
      "---------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dl__wide_hardtanh_preds = model_trainer_wrapper(\n",
    "    \"Wide HardTanh\", \n",
    "    [[25, 256], [256, 128], [128, 64], [64, 1]], \n",
    "    torch.nn.Hardtanh()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Networks underlying _HardTanh_ exhibit superior initial data fits, by default, as compared to width-tuned alternatives. Although convergence tendencies gravitate towards similar regions over epochs. Default leads in convergence by epochs, followed by narrow and then wide alternatives, before overfitting, indicated by early stoppage. Convergence, yet only in fairly similar regions, suggesting a better fit with wider networks. More dispersed regions may be caused, due to lack of patience in early stoppage, as indicated in the default case. Indication as of comparable behavior to the wide network until shortly prior cutoff, well below the epochs of the other.\n",
    "\n",
    "Improvement in fit, paired with overfitting onset, possibly disrupted by lack of patience in the _HardTanh_'s default case, suggests more complex patterns to be captured, as capacity increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 150%; text-align: center; border-radius: 10px 10px;\">6.2 - Evaluation</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improvements are put to the test based on unseen data. Towards proving the claim of improvements, explored networks are directly compared. Upon proof, improvements are questioned by baselines to judge their meaningfulness. As judged by the _MAPE_, complemented by R-squared _(R2)_. _R2_ as goodness of fit measure, indicative of the extent to which models explain rental rates by rental property's collective variance. That essentially delineates the range of rental rates covered, i.e. the spectrum of tenants reached. Given the overarching goal of stimulating global tenant-landlord interactions, irrespective of specific target groups, _R2_ makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(algos, ord, tars, preds):\n",
    "    return pd.DataFrame(\n",
    "        data = [\n",
    "            {\n",
    "                \"algorithm\": algo,\n",
    "                \"partition\": ptn,\n",
    "                \"MAPE\": mean_absolute_percentage_error(\n",
    "                    y_true = ptn_tar,\n",
    "                    y_pred = ptn_pred\n",
    "                ),\n",
    "                \"R2\": r2_score(\n",
    "                    y_true = ptn_tar,\n",
    "                    y_pred = ptn_pred\n",
    "                )\n",
    "            }\n",
    "            for algo, ptns_pred in zip(algos, preds)\n",
    "            for ptn, ptn_tar, ptn_pred in zip(ord, tars, ptns_pred)\n",
    "        ]\n",
    "    ).sort_values(\n",
    "        by = \"MAPE\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluation(\n",
    "    algos = [\n",
    "        \"dummy_regressor\",\n",
    "        \"linear_regression\",\n",
    "        \"dl_default_prelu\", \n",
    "        \"dl_default_hardtanh\", \n",
    "        \"dl_wide_prelu\", \n",
    "        \"dl_wide_hardtanh\", \n",
    "        \"dl_narrow_prelu\", \n",
    "        \"dl_narrow_hardtanh\"\n",
    "    ],\n",
    "    ord = [\n",
    "        \"train\", \n",
    "        \"val\", \n",
    "        \"test\"\n",
    "    ],\n",
    "    tars = [\n",
    "        y_train,\n",
    "        y_val,\n",
    "        y_test\n",
    "    ],\n",
    "    preds = [\n",
    "        dmy__preds,\n",
    "        ml__preds,\n",
    "        dl__dflt_prelu_preds, \n",
    "        dl__dflt_hardtanh_preds,\n",
    "        dl__wide_prelu_preds,\n",
    "        dl__wide_hardtanh_preds,\n",
    "        dl__narrow_prelu_preds,\n",
    "        dl__narrow_hardtanh_preds\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partition(df, ptn_col, ptn):\n",
    "    return df[df[ptn_col] == ptn].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>partition</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dl_wide_prelu</td>\n",
       "      <td>test</td>\n",
       "      <td>0.125676</td>\n",
       "      <td>0.779809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dl_default_prelu</td>\n",
       "      <td>test</td>\n",
       "      <td>0.127277</td>\n",
       "      <td>0.770835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dl_narrow_prelu</td>\n",
       "      <td>test</td>\n",
       "      <td>0.133673</td>\n",
       "      <td>0.765628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dl_wide_hardtanh</td>\n",
       "      <td>test</td>\n",
       "      <td>0.136122</td>\n",
       "      <td>0.774841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dl_default_hardtanh</td>\n",
       "      <td>test</td>\n",
       "      <td>0.148259</td>\n",
       "      <td>0.748661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dl_narrow_hardtanh</td>\n",
       "      <td>test</td>\n",
       "      <td>0.156497</td>\n",
       "      <td>0.742014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>linear_regression</td>\n",
       "      <td>test</td>\n",
       "      <td>0.177715</td>\n",
       "      <td>0.749245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dummy_regressor</td>\n",
       "      <td>test</td>\n",
       "      <td>0.355562</td>\n",
       "      <td>-0.136345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             algorithm partition      MAPE        R2\n",
       "0        dl_wide_prelu      test  0.125676  0.779809\n",
       "1     dl_default_prelu      test  0.127277  0.770835\n",
       "2      dl_narrow_prelu      test  0.133673  0.765628\n",
       "3     dl_wide_hardtanh      test  0.136122  0.774841\n",
       "4  dl_default_hardtanh      test  0.148259  0.748661\n",
       "5   dl_narrow_hardtanh      test  0.156497  0.742014\n",
       "6    linear_regression      test  0.177715  0.749245\n",
       "7      dummy_regressor      test  0.355562 -0.136345"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_partition(results, \"partition\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions based on the test partition confirm the initial assumption, wherefore _MAPE_ decreases with increasing width. Assuming lack of patience for _HardTanh_'s defaults, a tendency to adhere to wider alternatives was observed. _PReLU_ dominates _HardTanh_, irrespective of width, outperforming all alternatives. _HardTanh_'s wide alternative resembles _PReLU_, thus, at its worst. Even so, all neural networks are significantly above the dummy and slightly ahead of linear regression. With the gap between linear regression and the top neural network being more pronounced. As regards _R2_, linear regression is far closer, overtaking the narrow and default _HardTanh_, whereas the dummy trailed far behind. _R2_ for neural networks follows the same dynamic as the _MAPE_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>partition</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dl_wide_prelu</td>\n",
       "      <td>val</td>\n",
       "      <td>0.120425</td>\n",
       "      <td>0.827904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dl_default_prelu</td>\n",
       "      <td>val</td>\n",
       "      <td>0.122443</td>\n",
       "      <td>0.822616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dl_narrow_prelu</td>\n",
       "      <td>val</td>\n",
       "      <td>0.129452</td>\n",
       "      <td>0.820061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dl_wide_hardtanh</td>\n",
       "      <td>val</td>\n",
       "      <td>0.130997</td>\n",
       "      <td>0.825156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dl_default_hardtanh</td>\n",
       "      <td>val</td>\n",
       "      <td>0.139377</td>\n",
       "      <td>0.803650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dl_narrow_hardtanh</td>\n",
       "      <td>val</td>\n",
       "      <td>0.150519</td>\n",
       "      <td>0.786868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>linear_regression</td>\n",
       "      <td>val</td>\n",
       "      <td>0.168840</td>\n",
       "      <td>0.795403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dummy_regressor</td>\n",
       "      <td>val</td>\n",
       "      <td>0.340722</td>\n",
       "      <td>-0.108370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             algorithm partition      MAPE        R2\n",
       "0        dl_wide_prelu       val  0.120425  0.827904\n",
       "1     dl_default_prelu       val  0.122443  0.822616\n",
       "2      dl_narrow_prelu       val  0.129452  0.820061\n",
       "3     dl_wide_hardtanh       val  0.130997  0.825156\n",
       "4  dl_default_hardtanh       val  0.139377  0.803650\n",
       "5   dl_narrow_hardtanh       val  0.150519  0.786868\n",
       "6    linear_regression       val  0.168840  0.795403\n",
       "7      dummy_regressor       val  0.340722 -0.108370"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_partition(results, \"partition\", \"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test partition assertions are largely applicable to validation. Given a validation-rooted optimal state, neural network metrics improved slightly. _R2_ superiority of linear regression, thus diminished to only narrow _HardTanh_. As linear regression, although not exposed to the validation partition, also improved, simpler patterns may be assumed. Abounding from the fact that the dummy also improved, features near the median are to be expected, suggesting fewer outliers. Data leakage may therefore be smaller than anticipated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>partition</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dl_wide_prelu</td>\n",
       "      <td>train</td>\n",
       "      <td>0.100383</td>\n",
       "      <td>0.889597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dl_default_prelu</td>\n",
       "      <td>train</td>\n",
       "      <td>0.107640</td>\n",
       "      <td>0.880241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dl_narrow_prelu</td>\n",
       "      <td>train</td>\n",
       "      <td>0.119607</td>\n",
       "      <td>0.861756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dl_wide_hardtanh</td>\n",
       "      <td>train</td>\n",
       "      <td>0.127999</td>\n",
       "      <td>0.846000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dl_default_hardtanh</td>\n",
       "      <td>train</td>\n",
       "      <td>0.142747</td>\n",
       "      <td>0.825158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dl_narrow_hardtanh</td>\n",
       "      <td>train</td>\n",
       "      <td>0.150956</td>\n",
       "      <td>0.797746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>linear_regression</td>\n",
       "      <td>train</td>\n",
       "      <td>0.171145</td>\n",
       "      <td>0.826318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dummy_regressor</td>\n",
       "      <td>train</td>\n",
       "      <td>0.366044</td>\n",
       "      <td>-0.135670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             algorithm partition      MAPE        R2\n",
       "0        dl_wide_prelu     train  0.100383  0.889597\n",
       "1     dl_default_prelu     train  0.107640  0.880241\n",
       "2      dl_narrow_prelu     train  0.119607  0.861756\n",
       "3     dl_wide_hardtanh     train  0.127999  0.846000\n",
       "4  dl_default_hardtanh     train  0.142747  0.825158\n",
       "5   dl_narrow_hardtanh     train  0.150956  0.797746\n",
       "6    linear_regression     train  0.171145  0.826318\n",
       "7      dummy_regressor     train  0.366044 -0.135670"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_partition(results, \"partition\", \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training partition is subject to the same assumptions as validation, except for the simpler patterns and linear regression exposure. Simple patterns and fewer outliers in validation are supported by increased _MAPE_ for both dummy and linear regression. Especially so, as linear regression was exposed to the evaluation partition, yet still performed worse than for validation. Given that all models have been trained on those assumption-wise more complex patterns, the linear regression _R2_ again exceeds narrow and default _HardTanh_. Overall, all other metrics except for the dummy, not affected by data leakage, improved.\n",
    "\n",
    "In summary, unseen data poses _MAPE_ not very different from seen data, indicating generalizability. While _R2_ may be less, yet still in line with the experiment goal. With regard to the largely similar sizes of gaps across the underlying activation functions, a regular generalization gap may be apparent. In this respect, most baselines were surpassed, more so in the case of dominant neural networks, thereby passing the sanity check.\n",
    "\n",
    "Moreover, wider gaps were observed between the supposedly simpler validation and the more complex test partition, relative to linear regression and neural networks. Linear regression may, thus, struggle with outliers, as compared to neural networks. Data leakage in neural networks for the validation partition only emphasizes, as the gap should potentially be even wider. However, as the nature of the individual partitions has not been confirmed, assumptions should be treated with caution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 150%; text-align: center; border-radius: 10px 10px;\">6.3 - Optimization</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization efforts are rooted in the dominant wide _PReLU_. Such optimization occurs across a defined grid of hyperparameters. Choice of hyperparameters relies on exploration raised assumptions. Those assumptions assert that improvement of metrics comes with increase of width. However, as default and wide _PReLU_ were fairly close, one cannot rule out whether the optimum lies somewhere between or beyond. Thus, layer hyperparameters are centered around the dominant wide _PReLU_, investigating wideness and narrowness, until the default. While for the _PReLU_ activation function, an exhaustive search covering a broad range of alphas is conducted. A comprehensive grid search is warranted given the lack of prior indications, except for the default value, whose effectiveness remains uncertain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"module__layers\": [\n",
    "        [[25, i * 32], [i * 32, i * 16], [i * 16, i * 8], [i * 8, 1]]\n",
    "        for i in range(5, 12)\n",
    "    ],\n",
    "    \"module__activation\": [\n",
    "        torch.nn.PReLU(init = 0.125 + i * 0.125)\n",
    "    for i in range(7)\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, neural networks are not natively supported by sklearn's grid search. For this purpose, skorch is employed, giving the multilayer perceptron a sklearn BaseEstimator interface. In this way, the multilayer perceptron is wrapped as a NeuralNetRegressor, sharing similar learning hyperparameters for consistency with prior training. Except for maximum epochs, reduced to 150. 150 as approximately double that of exploration to avoid underfitting, while reducing runtime. In this instance, early stoppage is not utilized to limit epochs, as doing so would require an internal skorch split. Yet there is no back-channel, communicating validation partitions to the grid search. As a consequence, the validation partition would be ignored in the grid search, further reducing limited data. Limited diversity within data results in lack of generalizability. Thus, performance is given precedence over runtime. Performance is measured using the _MAPE_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update model trainer's hyperparameters\n",
    "trainer.updt_hparms(\n",
    "    max_epochs = 150,\n",
    "    opt_eval = \"neg_mean_absolute_percentage_error\"\n",
    "    )\n",
    "\n",
    "#construct NeuralNetRegressor wrapper\n",
    "trainer.init_estimator(\n",
    "    estimator = MultiLayerPerceptron,\n",
    "    dflt_lays = [[25, 256], [256, 128], [128, 64], [64, 1]],\n",
    "    dflt_act = torch.nn.PReLU()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation is conducted to obtain robust performance estimates. Robust, as a result of random fold splitting and role rotation, across multiple repetitions. Those roles constitute training and validation, consistent with neural networks' optimization. Hence, training and validation partitions are combined, split into four folds. Four folds to match the initial split of 25% validation and 75% training. Such folds lend themselves only to the stratification of targets. Therefore, stratification on community boards must be renounced. This lack of stratification is compensated for by 20 repetitions per hyperparameter combination. Compensated for, as the neural network will be exposed to multiple split combinations, eventually averaging out imbalances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 80 folds for each of 49 candidates, totalling 3920 fits\n"
     ]
    }
   ],
   "source": [
    "trainer.optimize(\n",
    "    grid = grid,\n",
    "    splts = 4,\n",
    "    reps = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'module__activation': PReLU(num_parameters=1),\n",
       " 'module__layers': [[25, 320], [320, 160], [160, 80], [80, 1]]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best hyperparameters\n",
    "trainer.reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best alpha of PReLU\n",
    "trainer.reg.best_params_[\"module__activation\"].weight.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-validated grid search supports the hypothesis of metric improvement in wide neural networks. Overly wide neural networks, however, risk memorizing data by heart. Overfitting therefore poses a serious concern among them. In line, no significant improvements, beyond the wide _PReLU_ default, were achieved. Performance was, nonetheless, tweaked by adding slightly wider layers. While _PReLU_'s default alpha proved most effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl__optimized_preds = trainer.inv_preds(\n",
    "    [\n",
    "        trainer.reg.best_estimator_.predict(ptn)\n",
    "        for ptn in prep.feats[1:]\n",
    "    ],\n",
    "    prep.tars_scaler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>partition</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dl_wide_prelu</td>\n",
       "      <td>test</td>\n",
       "      <td>0.125676</td>\n",
       "      <td>0.779809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>optimized_neural_network</td>\n",
       "      <td>test</td>\n",
       "      <td>0.127016</td>\n",
       "      <td>0.801977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  algorithm partition      MAPE        R2\n",
       "0             dl_wide_prelu      test  0.125676  0.779809\n",
       "1  optimized_neural_network      test  0.127016  0.801977"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = evaluation(\n",
    "    algos = [\n",
    "        \"dl_wide_prelu\",\n",
    "        \"optimized_neural_network\"\n",
    "    ],\n",
    "    ord = [\n",
    "        \"test\"\n",
    "    ],\n",
    "    tars = [\n",
    "        y_test\n",
    "    ],\n",
    "    preds = [\n",
    "        [dl__wide_prelu_preds[2]],\n",
    "        [dl__optimized_preds[2]]\n",
    "    ]\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be noted that the _MAPE_ for unseen data falls slightly above the explanatory one in this particular split. Even so, those hyperparameters outperformed the wide _PReLU_ default's ones across all folds and repetitions. The outperformance in this particular case could be attributed to a favorable split. Alternatively, grid search may have been affected due to community boards' absence of stratification. Besides that, _R2_ has improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#032765; font-family: newtimeroman; color: #ffffff; font-size: 200%; text-align: center; border-radius: 10px 10px;\">Task 7 - Conclusions and Future Work</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimental results are based on cross-validated neural networks, proven within a grid of hyperparameters. Hyperparameters focused on the architecture, rooted in prior explorations. Those explorations indicated performance improvements for increasing width, boosted by _PReLU_. As width optima remained speculative, layers revolved around the dominant neural network. While _PReLU_ alphas were exhaustively searched, given lack of evidence concerning the relative performance of the default. Based on the grid of those alphas and layers, the following hyperparameter combination emerged.\n",
    "\n",
    "- Layers: [[25, 320], [320, 160], [160, 80], [80, 1]]\n",
    "- PReLU Alpha: 0.25\n",
    "\n",
    "In consideration of those architectural hyperparameters, a _MAPE_ of 12.7% was achieved on yet unseen data, with _R2_ reaching 80.2%.\n",
    "\n",
    "This experiment's initial objective was proof of concept. Neural networks' reliability as an estimator of rental rates was therefore to be proven. Both dummy (by 22.85%) and linear regression (by 5.07%) were outperformed in a sanity check at a _MAPE_ of 12.7%. Thus there is evidence for greater reliability. While _R2_ indicates with 80.2%, coverage of a broad range of rental prices and thus spectrum of tenants. In line with the goal of general tenant-landlord stimulation.\n",
    "\n",
    "Due to these achievements, proof of concept is deemed successful, constituting a research scaling indicator. Such an indicator further reinforces an investment decision. This investment may revolutionize pricing strategies, alleviating landlord cold starts to attract potential tenants. Increased traffic attracts landlords owing to larger audiences, translating into listing fees as revenue.\n",
    "\n",
    "Yet, it may be wise to revisit classical machine learning before attempting to capitalize on these opportunities. As such, a full-fledged hyperparameter tuning is recommended, allowing for a fair comparison, as capitalization may be feasible via simpler approaches. The training should be supplemented with additional data to guarantee a fair representation of minority neighborhoods. In doing so, an even broader spectrum of nuances may be captured, eventually contributing to greater performance.\n",
    "\n",
    "Future Work:\n",
    "- Cross validated grid search for learning hyperparameters\n",
    "- Examination of hidden layer activation function combinations\n",
    "- Exploration of shallow and deep concepts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
